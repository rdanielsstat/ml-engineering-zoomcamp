{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00775a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.3.3\n",
      "Janitor version: 0.32.1\n",
      "Numpy version: 2.3.4\n",
      "Fastparquet version: 2024.11.0\n",
      "Scikit-learn version: 1.7.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import janitor\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from importlib.metadata import version\n",
    "\n",
    "print(\"Pandas version: \" + str(pd.__version__))\n",
    "print(\"Janitor version: \" + str(janitor.__version__))\n",
    "print(\"Numpy version: \" + str(np.__version__))\n",
    "print(\"Fastparquet version: \" + str(version(\"fastparquet\")))\n",
    "print(\"Scikit-learn version: \" + str(version(\"scikit-learn\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c28b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define column data types\n",
    "dtype_map = {\n",
    "    \"Health Service Area\": \"string\",\n",
    "    \"Hospital County\": \"string\",\n",
    "    \"Operating Certificate Number\": \"string\",\n",
    "    \"Permanent Facility Id\": \"string\",\n",
    "    \"Facility Name\": \"string\",\n",
    "    \"Age Group\": \"string\",\n",
    "    \"Zip Code\": \"string\",\n",
    "    \"Gender\": \"string\",\n",
    "    \"Race\": \"string\",\n",
    "    \"Ethnicity\": \"string\",\n",
    "    \"Length of Stay\": \"string\",\n",
    "    \"Type of Admission\": \"string\",\n",
    "    \"Patient Disposition\": \"string\",\n",
    "    \"Discharge Year\": \"string\",\n",
    "    \"CCSR Diagnosis Code\": \"string\",\n",
    "    \"CCSR Diagnosis Description\": \"string\",\n",
    "    \"CCSR Procedure Code\": \"string\",\n",
    "    \"CCSR Procedure Description\": \"string\",\n",
    "    \"APR DRG Code\": \"string\",\n",
    "    \"APR DRG Description\": \"string\",\n",
    "    \"APR MDC Code\": \"string\",\n",
    "    \"APR MDC Description\": \"string\",\n",
    "    \"APR Severity of Illness Code\": \"string\",\n",
    "    \"APR Severity of Illness Description\": \"string\",\n",
    "    \"APR Risk of Mortality\": \"string\",\n",
    "    \"APR Medical Surgical Description\": \"string\",\n",
    "    \"Payment Typology 1\": \"string\",\n",
    "    \"Payment Typology 2\": \"string\",\n",
    "    \"Payment Typology 3\": \"string\",\n",
    "    \"Birth Weight\": \"string\",\n",
    "    \"Emergency Department Indicator\": \"string\",\n",
    "    \"Total Charges\": \"float64\",\n",
    "    \"Total Costs\": \"float64\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf0c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data, clean names, subset, and print first 5 rows\n",
    "df_in = pd.read_csv('../data/untouched/Hospital_Inpatient_Discharges_(SPARCS_De-Identified)__2024_20251106.csv', dtype = dtype_map)\n",
    "\n",
    "df_in = df_in.clean_names()\n",
    "\n",
    "df_in = df_in[df_in['ccsr_diagnosis_description'] == 'INFLUENZA'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f312820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_in.copy()\n",
    "\n",
    "# replace missing facility characteristics with \"NAA\" (i.e., N/A abortion-related)\n",
    "missing_cols_abortion = ['health_service_area', 'hospital_county', 'operating_certificate_number', \n",
    "                         'permanent_facility_id', 'zip_code']\n",
    "\n",
    "df_clean.loc[df_clean['facility_name'] == 'Redacted for Confidentiality', missing_cols_abortion] = (\n",
    "    df_clean.loc[df_clean['facility_name'] == 'Redacted for Confidentiality', missing_cols_abortion].fillna('NAA')\n",
    ")\n",
    "\n",
    "# replace other missing zip_code values with \"NAS\" (i.e., N/A small sample)\n",
    "df_clean.loc[df_clean['facility_name'] != 'Redacted for Confidentiality', 'zip_code'] = \\\n",
    "    df_clean.loc[df_clean['facility_name'] != 'Redacted for Confidentiality', 'zip_code'].fillna('NAS')\n",
    "\n",
    "# convert 120+ length_of_stay values to 120\n",
    "df_clean['length_of_stay'] = df_clean['length_of_stay'].replace('120+', 120).astype('int64')\n",
    "\n",
    "# payment_typology_2, payment_typology_3, ccsr_procedure_description\n",
    "df_clean['payment_typology_2'] = df_clean['payment_typology_2'].fillna(\"None\")\n",
    "df_clean['payment_typology_3'] = df_clean['payment_typology_3'].fillna(\"None\")\n",
    "df_clean['ccsr_procedure_description'] =df_clean['ccsr_procedure_description'].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01a16067",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"drop redundent and unusable columns\n",
    "   - operating_certificate_number and facility_name are redundant with permanent_facility_id and not as granular, keep permanent_facility_id only\n",
    "   - discharge_year, ccsr_diagnosis_code, and ccsr_diagnosis_description have no variation (only 1 value)\n",
    "   - ccsr_procedure_code, apr_drg_code, apr_mdc_code, and apr_severity_of_illness_code are redundent\n",
    "   - birth_weight is 99.5% missing\n",
    "   - total_charges and total_costs will be dropped because they would not be known during the visit and are partially derived from length of stay\n",
    "\"\"\"\n",
    "df_clean.drop(['operating_certificate_number', 'facility_name', 'discharge_year', \n",
    "               'ccsr_procedure_code', 'apr_drg_code', 'apr_mdc_code', 'apr_severity_of_illness_code', \n",
    "               'ccsr_diagnosis_code', 'ccsr_diagnosis_description', 'birth_weight', \n",
    "               'total_charges', 'total_costs'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dccc29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['log_length_of_stay'] = np.log(df_clean['length_of_stay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afad2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_small_group_mapping(df, feature, min_count = 20):\n",
    "    \"\"\"combine all small categories into 'Other'\"\"\"\n",
    "    value_counts = df[feature].value_counts()\n",
    "    small_categories = value_counts[value_counts < min_count].index.tolist()\n",
    "    \n",
    "    return {cat: 'Other' for cat in small_categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9efd77f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mappings = {}\n",
    "\n",
    "category_mappings = {\n",
    "    'health_service_area': {\n",
    "        'Southern Tier': 'Southern Tier/Other',\n",
    "        'NAA':           'Southern Tier/Other'        \n",
    "    },\n",
    "    'gender': {\n",
    "        'F': 'F/U',\n",
    "        'U': 'F/U'\n",
    "    },\n",
    "    'ethnicity': {\n",
    "        'Multi-ethnic': 'Multi-ethnic/Unknown',\n",
    "        'Unknown': 'Multi-ethnic/Unknown'        \n",
    "    },\n",
    "    'type_of_admission': {\n",
    "        'Elective': 'Elective/Trauma/Other',\n",
    "        'Trauma': 'Elective/Trauma/Other',\n",
    "        'Not Available': 'Elective/Trauma/Other'\n",
    "    },\n",
    "    'payment_typology_1': {\n",
    "        'Federal/State/Local/VA': 'Miscellaneous/Other',\n",
    "        'Department of Corrections': 'Miscellaneous/Other'\n",
    "    },\n",
    "    'payment_typology_3': {\n",
    "        'Medicare': 'Miscellaneous/Other',\n",
    "        'Federal/State/Local/VA': 'Miscellaneous/Other',\n",
    "        'Managed Care, Unspecified': 'Miscellaneous/Other'\n",
    "    }\n",
    "}\n",
    "\n",
    "df = df_clean.copy()\n",
    "\n",
    "category_mappings['hospital_county'] = create_small_group_mapping(df, 'hospital_county', min_count = 20)\n",
    "category_mappings['permanent_facility_id'] = create_small_group_mapping(df, 'permanent_facility_id', min_count = 20)\n",
    "category_mappings['zip_code'] = create_small_group_mapping(df, 'zip_code', min_count = 20)\n",
    "category_mappings['patient_disposition'] = create_small_group_mapping(df, 'patient_disposition', min_count = 20)\n",
    "category_mappings['ccsr_procedure_description'] = create_small_group_mapping(df, 'ccsr_procedure_description', min_count = 20)\n",
    "category_mappings['apr_drg_description'] = create_small_group_mapping(df, 'apr_drg_description', min_count = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82ff44cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply all mappings at once\n",
    "for feature, mapping in category_mappings.items():\n",
    "    df[feature] = df[feature].replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eff45bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5769, 722, 722)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into 80/10/10\n",
    "X = df.drop(columns = ['length_of_stay', 'log_length_of_stay'])\n",
    "y = df['log_length_of_stay']\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size = 0.1, random_state = 42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size = 0.1111111, random_state = 42  # 0.1 / 0.9 = 0.1111111\n",
    ")\n",
    "\n",
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abd23c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target encoding\n",
    "\n",
    "# initialize; target_type = 'continuous' for regression; smooth ='auto' handles unseen categories and adds regularization\n",
    "encoder = TargetEncoder(target_type = 'continuous', smooth = 'auto', random_state = 42)\n",
    "\n",
    "# fit on training data only\n",
    "X_train_encoded = encoder.fit_transform(X_train, y_train)\n",
    "\n",
    "# transform validation and test (handles unseen categories automatically)\n",
    "X_val_encoded = encoder.transform(X_val)\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "# convert back to DataFrames\n",
    "X_train_encoded = pd.DataFrame(X_train_encoded, columns = X_train.columns, index = X_train.index)\n",
    "X_val_encoded = pd.DataFrame(X_val_encoded, columns = X_val.columns, index = X_val.index)\n",
    "X_test_encoded = pd.DataFrame(X_test_encoded, columns = X_test.columns, index = X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d86dc64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# lasso regression - which features can be removed?\\n# standardize predictors\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train_encoded)\\nX_val_scaled = scaler.transform(X_val_encoded)\\n\\n# lasso model\\nlasso = Lasso(alpha = 0.001, max_iter = 10000)\\nlasso.fit(X_train_scaled, y_train)\\n\\ncoef_df = pd.DataFrame({\\n    \"feature\": X_train_encoded.columns,\\n    \"coefficient\": lasso.coef_\\n})\\n\\n# features removed (coefficient exactly 0)\\nremoved_features = coef_df[coef_df[\"coefficient\"] == 0][\"feature\"].tolist()\\nprint(\"Features removed by Lasso (coef = 0):\")\\nprint(removed_features)\\n\\n# features retained\\nretained_features = coef_df[coef_df[\"coefficient\"] != 0][\"feature\"].tolist()\\nprint(f\"\\nNumber of retained features: {len(retained_features)}\")\\nprint(\"Some retained features:\")\\nprint(retained_features)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# lasso regression - which features can be removed?\n",
    "# standardize predictors\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_val_scaled = scaler.transform(X_val_encoded)\n",
    "\n",
    "# lasso model\n",
    "lasso = Lasso(alpha = 0.001, max_iter = 10000)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": X_train_encoded.columns,\n",
    "    \"coefficient\": lasso.coef_\n",
    "})\n",
    "\n",
    "# features removed (coefficient exactly 0)\n",
    "removed_features = coef_df[coef_df[\"coefficient\"] == 0][\"feature\"].tolist()\n",
    "print(\"Features removed by Lasso (coef = 0):\")\n",
    "print(removed_features)\n",
    "\n",
    "# features retained\n",
    "retained_features = coef_df[coef_df[\"coefficient\"] != 0][\"feature\"].tolist()\n",
    "print(f\"\\nNumber of retained features: {len(retained_features)}\")\n",
    "print(\"Some retained features:\")\n",
    "print(retained_features)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e5d649e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# subset training and validation sets to retained features\\nX_train_reduced = X_train_encoded[retained_features]\\nX_val_reduced = X_val_encoded[retained_features]\\n\\n# fit OLS on log-transformed target\\nols_reduced = LinearRegression()\\nols_reduced.fit(X_train_reduced, y_train)\\n\\n# predict on validation set (log scale)\\ny_val_pred_log = ols_reduced.predict(X_val_reduced)\\n\\n# back-transform to original scale\\ny_val_pred = np.exp(y_val_pred_log)\\ny_val_orig = np.exp(y_val)\\n\\n# evaluate\\nrmse = np.sqrt(mean_squared_error(y_val_orig, y_val_pred))\\nmae = mean_absolute_error(y_val_orig, y_val_pred)\\nr2 = r2_score(y_val_orig, y_val_pred)\\n\\nprint(\"OLS on lasso-selected features (log scale, evaluated on original scale):\")\\nprint(f\"RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# subset training and validation sets to retained features\n",
    "X_train_reduced = X_train_encoded[retained_features]\n",
    "X_val_reduced = X_val_encoded[retained_features]\n",
    "\n",
    "# fit OLS on log-transformed target\n",
    "ols_reduced = LinearRegression()\n",
    "ols_reduced.fit(X_train_reduced, y_train)\n",
    "\n",
    "# predict on validation set (log scale)\n",
    "y_val_pred_log = ols_reduced.predict(X_val_reduced)\n",
    "\n",
    "# back-transform to original scale\n",
    "y_val_pred = np.exp(y_val_pred_log)\n",
    "y_val_orig = np.exp(y_val)\n",
    "\n",
    "# evaluate\n",
    "rmse = np.sqrt(mean_squared_error(y_val_orig, y_val_pred))\n",
    "mae = mean_absolute_error(y_val_orig, y_val_pred)\n",
    "r2 = r2_score(y_val_orig, y_val_pred)\n",
    "\n",
    "print(\"OLS on lasso-selected features (log scale, evaluated on original scale):\")\n",
    "print(f\"RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "001f0e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OLS with standardized features (evaluated on original scale):\n",
      "RMSE: 4.631, MAE: 2.149, R2: 0.442\n"
     ]
    }
   ],
   "source": [
    "# fit the model with standardized features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_val_scaled = scaler.transform(X_val_encoded)\n",
    "\n",
    "# convert back to DataFrame to keep feature names\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns = X_train_encoded.columns, index = X_train_encoded.index)\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns = X_val_encoded.columns, index = X_val_encoded.index)\n",
    "\n",
    "# refit OLS on standardized data\n",
    "ols_standardized = LinearRegression()\n",
    "ols_standardized.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predict (log scale)\n",
    "y_val_pred_log_std = ols_standardized.predict(X_val_scaled)\n",
    "\n",
    "# back-transform to original scale\n",
    "y_val_pred = np.exp(y_val_pred_log_std)\n",
    "y_val_orig = np.exp(y_val)\n",
    "\n",
    "# evaluate (should be very similar performance)\n",
    "y_val_pred_std = np.exp(y_val_pred_log_std)\n",
    "rmse_std = np.sqrt(mean_squared_error(y_val_orig, y_val_pred_std))\n",
    "mae_std = mean_absolute_error(y_val_orig, y_val_pred_std)\n",
    "r2_std = r2_score(y_val_orig, y_val_pred_std)\n",
    "\n",
    "print(\"\\nOLS with standardized features (evaluated on original scale):\")\n",
    "print(f\"RMSE: {rmse_std:.3f}, MAE: {mae_std:.3f}, R2: {r2_std:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba262a4a",
   "metadata": {},
   "source": [
    "Above is the full clean pipeline. Package the steps and save it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2004a50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline saved!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class LOSPipeline:\n",
    "    def __init__(self, encoder, scaler, model, features, category_mappings = None):\n",
    "        self.encoder = encoder\n",
    "        self.scaler = scaler\n",
    "        self.model = model\n",
    "        self.features = features\n",
    "        self.category_mappings = category_mappings or {}\n",
    "    \n",
    "    def preprocess(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Fill missing values safely\n",
    "        missing_cols_abortion = ['health_service_area', 'hospital_county', 'operating_certificate_number',\n",
    "                                'permanent_facility_id', 'zip_code']\n",
    "        \n",
    "        if 'facility_name' in df.columns:\n",
    "            # Fill NA with empty string to safely compare\n",
    "            facility_name_filled = df['facility_name'].fillna('')\n",
    "            mask = facility_name_filled == \"Redacted for Confidentiality\"\n",
    "            df.loc[mask, missing_cols_abortion] = df.loc[mask, missing_cols_abortion].fillna(\"NAA\")\n",
    "            df.loc[~mask, 'zip_code'] = df.loc[~mask, 'zip_code'].fillna(\"NAS\")\n",
    "        else:\n",
    "            # No facility_name column â€” just fill defaults\n",
    "            df.loc[:, 'zip_code'] = df.loc[:, 'zip_code'].fillna(\"NAS\")\n",
    "        \n",
    "        # Fill other NA columns\n",
    "        for col in ['payment_typology_2', 'payment_typology_3', 'ccsr_procedure_description']:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].fillna(\"None\")\n",
    "        \n",
    "        # Apply category mappings\n",
    "        for feature, mapping in self.category_mappings.items():\n",
    "            if feature in df.columns:\n",
    "                df[feature] = df[feature].replace(mapping)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def predict(self, df):\n",
    "        df = self.preprocess(df)\n",
    "        \n",
    "        # Ensure all features exist\n",
    "        for col in self.features:\n",
    "            if col not in df.columns:\n",
    "                df[col] = \"None\"\n",
    "        \n",
    "        # Subset to features in correct order\n",
    "        df_features = df[self.features]\n",
    "        \n",
    "        # Target encoding\n",
    "        df_encoded = self.encoder.transform(df_features)\n",
    "        \n",
    "        # Convert back to DataFrame\n",
    "        df_encoded = pd.DataFrame(df_encoded, columns=self.features)\n",
    "        \n",
    "        # Standardize\n",
    "        df_scaled = self.scaler.transform(df_encoded)\n",
    "        \n",
    "        # Convert back to DataFrame\n",
    "        df_scaled = pd.DataFrame(df_scaled, columns=self.features)\n",
    "        \n",
    "        # Predict log-length-of-stay and back-transform\n",
    "        log_pred = self.model.predict(df_scaled)\n",
    "        return np.exp(log_pred)\n",
    "\n",
    "# -------------------------\n",
    "# save pipeline\n",
    "# -------------------------\n",
    "pipeline = LOSPipeline(\n",
    "    encoder = encoder,\n",
    "    scaler = scaler,\n",
    "    model = ols_standardized,\n",
    "    features = list(encoder.feature_names_in_),  # All 20 features\n",
    "    category_mappings = category_mappings\n",
    ")\n",
    "\n",
    "with open(\"../app/pipeline_v1.bin\", \"wb\") as f_out:\n",
    "    pickle.dump(pipeline, f_out)\n",
    "print(\"Pipeline saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79a4f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_point = {\n",
    "    'health_service_area': 'New York City',\n",
    "    'hospital_county': 'New York',\n",
    "    'operating_certificate_number': '7002032',\n",
    "    'permanent_facility_id': '001469',\n",
    "    'facility_name': 'MOUNT SINAI MORNINGSIDE',\n",
    "    'age_group': '70 or Older',\n",
    "    'zip_code': '100',\n",
    "    'gender': 'F',\n",
    "    'race': 'Other Race',\n",
    "    'ethnicity': 'Spanish/Hispanic',\n",
    "    'length_of_stay': 3,\n",
    "    'type_of_admission': 'Emergency',\n",
    "    'patient_disposition': 'Home w/ Home Health Services',\n",
    "    'discharge_year': 2024,\n",
    "    'ccsr_diagnosis_code': 'RSP003',\n",
    "    'ccsr_diagnosis_description': 'INFLUENZA',\n",
    "    'ccsr_procedure_code': pd.NA,\n",
    "    'ccsr_procedure_description': pd.NA,\n",
    "    'apr_drg_code': '113',\n",
    "    'apr_drg_description': 'INFECTIONS OF UPPER RESPIRATORY TRACT',\n",
    "    'apr_mdc_code': '03',\n",
    "    'apr_mdc_description': 'EAR, NOSE, MOUTH, THROAT AND CRANIOFACIAL DISEASES',\n",
    "    'apr_severity_of_illness_code': '3',\n",
    "    'apr_severity_of_illness_description': 'Major',\n",
    "    'apr_risk_of_mortality': 'Major',\n",
    "    'apr_medical_surgical_description': 'Medical',\n",
    "    'payment_typology_1': 'Medicare',\n",
    "    'payment_typology_2': 'Medicare',\n",
    "    'payment_typology_3': pd.NA,\n",
    "    'birth_weight': pd.NA,\n",
    "    'emergency_department_indicator': 'Y',\n",
    "    'total_charges': 52009.26,\n",
    "    'total_costs': 11007.46\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f9cf7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted length of stay: 4.360550806716047\n"
     ]
    }
   ],
   "source": [
    "# convert to DataFrame\n",
    "df_test = pd.DataFrame([data_point])\n",
    "\n",
    "# predict\n",
    "pred = pipeline.predict(df_test)\n",
    "print(\"Predicted length of stay:\", pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f9397a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_point2 = {\n",
    "    'health_service_area': 'New York City',\n",
    "    'hospital_county': 'New York',\n",
    "    'operating_certificate_number': '7002032',\n",
    "    'permanent_facility_id': '001469',\n",
    "    'facility_name': 'MOUNT SINAI MORNINGSIDE',\n",
    "    'age_group': '70 or Older',\n",
    "    'zip_code': '100',\n",
    "    'gender': 'M',\n",
    "    'race': 'Other Race',\n",
    "    'ethnicity': 'Spanish/Hispanic',\n",
    "    'length_of_stay': 3,\n",
    "    'type_of_admission': 'Emergency',\n",
    "    'patient_disposition': 'Home w/ Home Health Services',\n",
    "    'discharge_year': 2024,\n",
    "    'ccsr_diagnosis_code': 'RSP003',\n",
    "    'ccsr_diagnosis_description': 'INFLUENZA',\n",
    "    'ccsr_procedure_code': pd.NA,\n",
    "    'ccsr_procedure_description': pd.NA,\n",
    "    'apr_drg_code': '113',\n",
    "    'apr_drg_description': 'INFECTIONS OF UPPER RESPIRATORY TRACT',\n",
    "    'apr_mdc_code': '03',\n",
    "    'apr_mdc_description': 'EAR, NOSE, MOUTH, THROAT AND CRANIOFACIAL DISEASES',\n",
    "    'apr_severity_of_illness_code': '3',\n",
    "    'apr_severity_of_illness_description': 'Major',\n",
    "    'apr_risk_of_mortality': 'Major',\n",
    "    'apr_medical_surgical_description': 'Medical',\n",
    "    'payment_typology_1': 'Medicare',\n",
    "    'payment_typology_2': 'Medicare',\n",
    "    'payment_typology_3': pd.NA,\n",
    "    'birth_weight': pd.NA,\n",
    "    'emergency_department_indicator': 'Y',\n",
    "    'total_charges': 52009.26,\n",
    "    'total_costs': 11007.46\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5aa38fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted length of stay: 4.250121581733489\n"
     ]
    }
   ],
   "source": [
    "# convert to DataFrame\n",
    "df_test2 = pd.DataFrame([data_point2])\n",
    "\n",
    "# predict\n",
    "pred = pipeline.predict(df_test2)\n",
    "print(\"Predicted length of stay:\", pred[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
